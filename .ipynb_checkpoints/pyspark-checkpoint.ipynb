{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef509c49-993e-49c1-855d-77c3425c736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing pyspark library to run spark in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214c8f5d-307c-4317-847a-cd9490f34402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\hanns\\anaconda3\\envs\\testing\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\users\\hanns\\anaconda3\\envs\\testing\\lib\\site-packages (from pyspark) (0.10.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "#we already install this library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a784d60-013a-409e-baf0-263dc00e182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3969b836-826f-4a2f-8202-065bcbee39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the library to start the session\n",
    "from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02e6aea-00fd-4d86-acc6-08d5d32ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of spark\n",
    "spark_runing = SparkSession.builder.appName('testing').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30aa48eb-76e7-4986-895d-cac405af4b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>testing</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x14fc3477df0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_runing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3eeb64-bc87-4ba4-8a21-9f2dcab32b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Krish</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sudhanshu</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  age  Experience  Salary\n",
       "0      Krish   31          10   30000\n",
       "1  Sudhanshu   30           8   25000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "demo_csv = pd.read_csv('test1.csv')\n",
    "demo_csv.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce8737-ec42-433f-807c-e63b3669be00",
   "metadata": {},
   "source": [
    "# read a dataset with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c2ad67e-fdb5-46c3-ad28-b18f712d3724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark = spark_runing.read.csv('test1.csv')\n",
    "#show a resume of what of its\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444b27f-5b56-4eb4-a982-601b82714753",
   "metadata": {},
   "source": [
    "With this command shows the whole table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f236ba-330e-4c99-9d44-3cc9fd0a2073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|      _c0|_c1|       _c2|   _c3|\n",
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show the data\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "208adaa0-a9c4-4115-9cdf-ebf192f6be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#une the title as title in the imported file\n",
    "#option() = alows to consider the 1st row as header\n",
    "\n",
    "df_pyspark_title = spark_runing.read.option('header','true').csv('test1.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c779b96-283b-434b-a82e-1729c94cfd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_title.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f97cc-e167-424c-a5d7-2835123ab8bb",
   "metadata": {},
   "source": [
    "### type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "098770c0-478f-4cae-a1f2-1a83bb47e6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying the type in spark\n",
    "type(df_pyspark_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae64afb1-b0d3-43d2-ac56-13a135f15026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verifying the type in pandas\n",
    "type(demo_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea90dff5-6650-4705-965d-30e537c7a9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#description of the dataset\n",
    "#this prin only strings cause we dont assign a type when importing\n",
    "df_pyspark_title.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7ecbe-f37b-42b2-8267-46eb7f548135",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e577d44f-9cda-4231-8b45-2fcc1f738d3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pyspark Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40df15-fd89-423c-ad90-41aa4cc3a3d7",
   "metadata": {},
   "source": [
    "* PySpark Dataframe\n",
    "* Reading The Dataset\n",
    "* Checking the Datatypes of the Column(Schema)\n",
    "* Selecting Columns And Indexing\n",
    "* Check Describe option similar to Pandas\n",
    "* Adding Columns\n",
    "* Dropping columns\n",
    "* Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d793963-515c-4d8a-bf61-9d54e675bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inferSchema = allows to got the datatype from thefile \n",
    "df_pyspark_title_inferSchema = spark_runing.read.option('header','true').csv('test1.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8404a426-6c10-455c-b0ba-3ede516c4a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_title_inferSchema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02349d1c-ae99-4f51-8a13-5a80049a4a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'age', 'Experience', 'Salary']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns all column names as a list.\n",
    "df_pyspark_title_inferSchema.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e68a671-04f0-4270-bd63-0b6873f2963a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Krish', age=31, Experience=10, Salary=30000),\n",
       " Row(Name='Sudhanshu', age=30, Experience=8, Salary=25000)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Returns the first ``n`` rows.\n",
    "df_pyspark_title_inferSchema.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed25781-7ee5-4bcf-a8a1-6b1ff2c2fce5",
   "metadata": {},
   "source": [
    "# selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bf5a37f-a97f-4273-bb0b-e513192270f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     name|\n",
      "+---------+\n",
      "|    Krish|\n",
      "|Sudhanshu|\n",
      "|    Sunny|\n",
      "|     Paul|\n",
      "|   Harsha|\n",
      "|  Shubham|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#selecting one column\n",
    "df_pyspark_title_inferSchema.select('name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f6cd3-73b0-4215-be58-70f492b613ce",
   "metadata": {},
   "source": [
    "selecting 2 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1268d17c-1817-4df5-8119-32bab9f62b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     name|salary|\n",
      "+---------+------+\n",
      "|    Krish| 30000|\n",
      "|Sudhanshu| 25000|\n",
      "|    Sunny| 20000|\n",
      "|     Paul| 20000|\n",
      "|   Harsha| 15000|\n",
      "|  Shubham| 18000|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_title_inferSchema.select(['name','salary']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff5539a-6b2d-48d9-8c7b-ecdd3f78acaf",
   "metadata": {},
   "source": [
    "cheking the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41353104-153b-4d6f-9d89-8370a3ee854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the data types\n",
    "df_pyspark_title_inferSchema.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d60ffed-daa4-43ef-89a2-d2b028237b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+-----------------+------------------+\n",
      "|summary|  Name|               age|       Experience|            Salary|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "|  count|     6|                 6|                6|                 6|\n",
      "|   mean|  null|26.333333333333332|4.666666666666667|21333.333333333332|\n",
      "| stddev|  null| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
      "|    min|Harsha|                21|                1|             15000|\n",
      "|    max| Sunny|                31|               10|             30000|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show the description in stadistics\n",
    "df_pyspark_title_inferSchema.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4d9d3-c70b-43b9-8152-2f575cbf5fe8",
   "metadata": {},
   "source": [
    "# adding column in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d5dca10-6af2-434d-b83e-63dfbe90ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark_add_column = df_pyspark_title_inferSchema.withColumn('experience after 2 years', df_pyspark_title_inferSchema['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c777afc-ee25-42b7-92cb-0bee806057fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+------------------------+\n",
      "|     Name|age|Experience|Salary|experience after 2 years|\n",
      "+---------+---+----------+------+------------------------+\n",
      "|    Krish| 31|        10| 30000|                      12|\n",
      "|Sudhanshu| 30|         8| 25000|                      10|\n",
      "|    Sunny| 29|         4| 20000|                       6|\n",
      "|     Paul| 24|         3| 20000|                       5|\n",
      "|   Harsha| 21|         1| 15000|                       3|\n",
      "|  Shubham| 23|         2| 18000|                       4|\n",
      "+---------+---+----------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_add_column.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1c7c5-0188-4a4c-a2fb-43bcf45cb999",
   "metadata": {},
   "source": [
    "# dropping the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06f56b11-2ef1-41db-84c5-0dd99e6cfafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark2 = df_pyspark_add_column .drop('experience after 2 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "344b2930-1b9a-4236-bb68-aac4142b11fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0897a9-d8e2-4813-bc74-75b1231c3074",
   "metadata": {},
   "source": [
    "# rename column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6a9ce81-5845-47b1-aa56-638a3e31af72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|      xxx|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark2.withColumnRenamed('name', 'xxx').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a360dc6-db26-4f2e-b31d-08034c867232",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3e561-c380-462e-88c3-e433b30e2af9",
   "metadata": {},
   "source": [
    "# Pyspark Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c948e75-f2c6-4455-b8f8-bb177a168aea",
   "metadata": {},
   "source": [
    "* Dropping Columns\n",
    "* Dropping Rows\n",
    "* Various Parameter In Dropping functionalities\n",
    "* Handling Missing values by Mean, MEdian And Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f492eb5-d23c-490a-81e3-28f9b04f8003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
